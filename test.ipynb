{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = [['I', 'enjoy', 'flying'], ['I', 'like', 'NLP'], ['I', 'like', 'deep', 'learning'], ['learning', 'deep']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|D| 4\n",
      "|V| 8\n",
      "|W| 12\n"
     ]
    }
   ],
   "source": [
    "vocabulary = set(['<UNK>'])\n",
    "word_count = 0\n",
    "\n",
    "for text in all_text:\n",
    "  vocabulary |= set(text)\n",
    "  word_count += len(text)\n",
    "    \n",
    "print('|D|', len(all_text))\n",
    "print('|V|', len(vocabulary))\n",
    "print('|W|', word_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31de649452ab427590f743dad4a43bec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "counts = {}\n",
    "for text in tqdm(all_text):\n",
    "  for word in text:\n",
    "    counts[word] = counts.get(word,0) + 1\n",
    "\n",
    "# for word in counts:\n",
    "#   if counts[word] < 4:\n",
    "#     vocabulary.remove(word)\n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab2index = {v:i for i,v in enumerate(vocabulary)}\n",
    "index2vocab = {i:v for i,v in enumerate(vocabulary)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'I': 0, '<UNK>': 1, 'deep': 2, 'like': 3, 'enjoy': 4, 'NLP': 5, 'flying': 6, 'learning': 7}\n",
      "{0: 'I', 1: '<UNK>', 2: 'deep', 3: 'like', 4: 'enjoy', 5: 'NLP', 6: 'flying', 7: 'learning'}\n"
     ]
    }
   ],
   "source": [
    "print(vocab2index)\n",
    "print(index2vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cooccurrences(texts,window):\n",
    "  cooccurrences = {}\n",
    "  for text in texts:\n",
    "    for i in range(len(text)):\n",
    "      for j in range(1, window + 1):\n",
    "        if(i+j < len(text)):\n",
    "          cooccurrences[(text[i], text[i+j])] =  cooccurrences.get((text[i], text[i+j]), 0) + 1\n",
    "  return cooccurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooccurrences = get_cooccurrences(all_text,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('I', 'enjoy'): 1,\n",
       " ('enjoy', 'flying'): 1,\n",
       " ('I', 'like'): 2,\n",
       " ('like', 'NLP'): 1,\n",
       " ('like', 'deep'): 1,\n",
       " ('deep', 'learning'): 1,\n",
       " ('learning', 'deep'): 1}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cooccurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "rows = []\n",
    "cols = []\n",
    "keys_list = list(cooccurrences.keys())\n",
    "keys_set = set()\n",
    "for keys in keys_list:\n",
    "  (word1, word2) = keys\n",
    "  if(keys not in keys_set):\n",
    "    reversed_keys = (word2, word1) \n",
    "    if(reversed_keys not in keys_set):\n",
    "      rows.append(vocab2index[word1])\n",
    "      cols.append(vocab2index[word2])\n",
    "      data.append(cooccurrences.get(keys) + cooccurrences.get(reversed_keys, 0))\n",
    "      rows.append(vocab2index[word2])\n",
    "      cols.append(vocab2index[word1])\n",
    "      data.append(cooccurrences.get(keys) + cooccurrences.get(reversed_keys, 0))\n",
    "      keys_set.add(keys)\n",
    "      keys_set.add(reversed_keys)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I enjoy 1\n",
      "enjoy I 1\n",
      "enjoy flying 1\n",
      "flying enjoy 1\n",
      "I like 2\n",
      "like I 2\n",
      "like NLP 1\n",
      "NLP like 1\n",
      "like deep 1\n",
      "deep like 1\n",
      "deep learning 2\n",
      "learning deep 2\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(rows)):\n",
    "  print(f'{index2vocab[rows[i]]} {index2vocab[cols[i]]} {data[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "cooccurrences = scipy.sparse.coo_matrix((data,(rows,cols)),shape=(len(vocab2index),len(vocab2index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 2, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 2],\n",
       "       [2, 0, 1, 0, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 2, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cooccurrences_array = cooccurrences.toarray()\n",
    "cooccurrences_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.07127648e-01  6.41170943e-01 -3.07883784e-01]\n",
      " [-6.47885395e-18  2.09004732e-17 -7.83207624e-20]\n",
      " [-5.48521597e-01  5.63836264e-01 -2.70748456e-01]\n",
      " [ 2.04959147e-01 -3.65355242e-01 -7.60855808e-01]\n",
      " [ 3.14015631e-01 -1.26886544e-01 -2.64242449e-01]\n",
      " [ 1.15265403e-01  2.73152958e-01 -1.31165280e-01]\n",
      " [ 1.76596843e-01  9.48650268e-02 -4.55532237e-02]\n",
      " [-5.90156343e-01 -1.94401464e-01 -4.04842920e-01]]\n",
      "[1.81807791 2.78545696 2.78545696]\n",
      "[[ 0.39818641  0.         -0.53647511  0.20956148  0.32106682  0.11273397\n",
      "   0.17271847 -0.60340824]\n",
      " [-0.30788378  0.         -0.27074846  0.76085581  0.26424245 -0.13116528\n",
      "  -0.04555322  0.40484292]\n",
      " [-0.64117094  0.         -0.56383626 -0.36535524 -0.12688654 -0.27315296\n",
      "  -0.09486503 -0.19440146]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ortho_group\n",
    "from scipy.sparse import csc_matrix, diags\n",
    "from scipy.sparse.linalg import svds\n",
    "#(cooccurrences:scipy.sparse.coo_matrix)->dict(str,np.array)\n",
    "def get_svd_word_vectors(cooccurrences):\n",
    "  word_vectors = {}\n",
    "  cooccurrences = cooccurrences.asfptype()\n",
    "  u2, s2, vT2 = svds(cooccurrences, k=3)\n",
    "  print(u2)\n",
    "  print(s2)\n",
    "  print(vT2)\n",
    "\n",
    "  return word_vectors\n",
    "\n",
    "svd_vecs = get_svd_word_vectors(cooccurrences)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "987212beba703396f74c33891dd08bb2b9cc492c8e998129248611de3ea7e409"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
